{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9977a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Viterbi Tagging Results \n",
      "\n",
      "Sentence: The cat meows\n",
      "Tags   : DET --> NOUN --> VERB\n",
      "Probability: 0.017578\n",
      "\n",
      "Sentence: My dog barks loudly\n",
      "Tags   : DET --> NOUN --> VERB --> ADV\n",
      "Probability: 0.000732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Training Data\n",
    "train_sentences = [\n",
    "    \"The_DET cat_NOUN sleeps_VERB\",\n",
    "    \"A_DET dog_NOUN barks_VERB\",\n",
    "    \"The_DET dog_NOUN sleeps_VERB\",\n",
    "    \"My_DET dog_NOUN runs_VERB fast_ADV\",\n",
    "    \"A_DET cat_NOUN meows_VERB loudly_ADV\",\n",
    "    \"Your_DET cat_NOUN runs_VERB\",\n",
    "    \"The_DET bird_NOUN sings_VERB sweetly_ADV\",\n",
    "    \"A_DET bird_NOUN chirps_VERB\"\n",
    "]\n",
    "\n",
    "tagged_data = []\n",
    "for sentence in train_sentences:\n",
    "    word_tag_pairs = sentence.strip().split()\n",
    "    tagged_sentence = [tuple(wt.rsplit('_', 1)) for wt in word_tag_pairs]\n",
    "    tagged_data.append(tagged_sentence)\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self):\n",
    "        self.states = set()\n",
    "        self.vocab = set()\n",
    "        self.start_probs = defaultdict(float)\n",
    "        self.trans_probs = defaultdict(lambda: defaultdict(float))\n",
    "        self.emit_probs = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    def train(self, tagged_sentences):\n",
    "        tag_counts = defaultdict(int)\n",
    "        transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "        emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "        start_counts = defaultdict(int)\n",
    "\n",
    "        for sentence in tagged_sentences:\n",
    "            prev_tag = None\n",
    "            for i, (word, tag) in enumerate(sentence):\n",
    "                self.states.add(tag)\n",
    "                self.vocab.add(word.lower())\n",
    "                tag_counts[tag] += 1\n",
    "                emission_counts[tag][word.lower()] += 1\n",
    "\n",
    "                if i == 0:\n",
    "                    start_counts[tag] += 1\n",
    "                if prev_tag is not None:\n",
    "                    transition_counts[prev_tag][tag] += 1\n",
    "                prev_tag = tag\n",
    "\n",
    "        total_starts = sum(start_counts.values())\n",
    "        for tag in self.states:\n",
    "            self.start_probs[tag] = start_counts[tag] / total_starts\n",
    "            for next_tag in self.states:\n",
    "                self.trans_probs[tag][next_tag] = (\n",
    "                    transition_counts[tag][next_tag] / tag_counts[tag]\n",
    "                )\n",
    "            for word in self.vocab:\n",
    "                self.emit_probs[tag][word] = (\n",
    "                    emission_counts[tag][word] / tag_counts[tag]\n",
    "                )\n",
    "\n",
    "    def viterbi(self, sentence):\n",
    "        V = [{}]\n",
    "        path = {}\n",
    "\n",
    "        for tag in self.states:\n",
    "            V[0][tag] = self.start_probs[tag] * self.emit_probs[tag].get(sentence[0], 1e-6)\n",
    "            path[tag] = [tag]\n",
    "\n",
    "        for t in range(1, len(sentence)):\n",
    "            V.append({})\n",
    "            new_path = {}\n",
    "\n",
    "            for curr_tag in self.states:\n",
    "                max_prob, best_prev_tag = max(\n",
    "                    (V[t - 1][prev_tag] * self.trans_probs[prev_tag].get(curr_tag, 1e-6) *\n",
    "                     self.emit_probs[curr_tag].get(sentence[t], 1e-6), prev_tag)\n",
    "                    for prev_tag in self.states\n",
    "                )\n",
    "                V[t][curr_tag] = max_prob\n",
    "                new_path[curr_tag] = path[best_prev_tag] + [curr_tag]\n",
    "\n",
    "            path = new_path\n",
    "\n",
    "        max_final_prob, best_final_tag = max((V[-1][tag], tag) for tag in self.states)\n",
    "        return path[best_final_tag], max_final_prob\n",
    "\n",
    "model = HMM()\n",
    "model.train(tagged_data)\n",
    "\n",
    "# Test Sentences\n",
    "test_sentences = [\n",
    "    \"The cat meows\",\n",
    "    \"My dog barks loudly\"\n",
    "]\n",
    "\n",
    "print(\" Viterbi Tagging Results \\n\")\n",
    "for sentence in test_sentences:\n",
    "    tokens = [w.lower() for w in sentence.split()]\n",
    "    best_tags, prob = model.viterbi(tokens)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(\"Tags   :\", \" --> \".join(best_tags))\n",
    "    print(f\"Probability: {prob:.6f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
